# Task_06_Deep_Fake

This repository contains my deliverables for **Research Task 6: Deep Fake**. It includes:
- AI-generated (or AI-assisted) interview **script**, **prompts**, **workflow documentation**, and **audio assets**.
- A reproducible **workflow** to generate voices with free/student tools and to assemble the final interview.
- Ethical considerations, risk notes, and time-tracking checklist.

> Instructor brief referenced: see course handout and email submission details. (Submission email: `jrstrome@syr.edu`).

## Repository Map
```
Task_06_Deep_Fake/
â”œâ”€ README.md
â”œâ”€ assets/
â”‚  â”œâ”€ interview_script.md
â”‚  â”œâ”€ interview_questions.md
â”‚  â””â”€ consent_and_ethics.md
â”œâ”€ prompts/
â”‚  â”œâ”€ system_prompt.txt
â”‚  â”œâ”€ interviewer_prompt.txt
â”‚  â””â”€ guest_prompt.txt
â”œâ”€ scripts/
â”‚  â”œâ”€ assemble_interview.py
â”‚  â”œâ”€ split_script.py
â”‚  â””â”€ coqui_tts_instructions.md
â”œâ”€ workflow/
â”‚  â”œâ”€ PROCESS.md
â”‚  â””â”€ TIME_REPORT_CHECKLIST.md
â”œâ”€ results/
â”‚  â”œâ”€ audio/
â”‚  â”‚  â”œâ”€ interview_host.wav
â”‚  â”‚  â”œâ”€ interview_guest.wav
â”‚  â”‚  â””â”€ interview_mix.wav
â”‚  â””â”€ figures/
â”‚     â””â”€ waveform_preview.png  (optional placeholder)
â””â”€ logs/
   â””â”€ run_log_2025-08-31.json
```


---

## ðŸ”§ Tools & Methods  

### Tools Explored  
- ðŸ—£ï¸ **ElevenLabs** â€“ natural voices, used for final host/guest audio.  
- ðŸ–¥ï¸ **Coqui TTS** â€“ open-source offline tool, tested for reproducibility.  
- ðŸŽ›ï¸ **Audacity / Online Audio Joiners** â€“ used for merging files when needed.  
- ðŸ **Python Scripts** â€“ automation for splitting and combining text/audio.  

### Workflow Summary  
1. Drafted **script** in `assets/interview_script.md`.  
2. Split into **host_lines.txt** and **guest_lines.txt`**.  
3. Generated audio separately in ElevenLabs (two different voices).  
4. Exported files â†’ `interview_host.wav` + `interview_guest.wav`.  
5. Combined them into **one file** â†’ `interview_mix.wav`.  
6. Documented process, ethics, and time reporting.  

---

## ðŸ”„ Process & Reflection  

### 1. Initial Planning  
- Converted narrative into Q&A dialogue with Host + Guest.  
- Wrote **role-based prompts** for clarity (system, host, guest).  

### 2. Tool Exploration  
- Tried **Coqui TTS** (free but robotic).  
- Settled on **ElevenLabs** (natural, but free tier has limits).  
- Used **Audacity / Python scripts** for audio assembly.  

### 3. Execution  
- Generated Host and Guest audio separately.  
- Merged into one interview file.  
- Added ethics statement & documentation.  

### 4. Challenges  
- ElevenLabs doesnâ€™t support true multi-speaker â†’ solved by generating separately.  
- Some mispronunciations required rewriting lines.  
- Balancing realism with ethics (ensured clear AI-labeling).  

### 5. Lessons Learned  
- **Process > Product** â†’ documenting choices/trade-offs is key.  
- Free tools are enough if combined smartly.  
- Reproducibility matters (scripts + repo structure).  

### 6. Reflection  
This task showed how to move from **static text** to **dynamic audio** while balancing technical, ethical, and workflow challenges. The final interview file is important, but the real value lies in the **structured process and clear documentation**.  

---

## ðŸ”Š Results  
- Final AI-generated interview:  


